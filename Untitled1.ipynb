{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9a3223e-b1dc-43d8-9f0a-347825eea267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desktop path: C:\\Users\\prisi\\Desktop\n",
      "File path: C:\\Users\\prisi\\Desktop\\ECI 2024 Party Wise Results.txt\n",
      "Desktop path exists: C:\\Users\\prisi\\Desktop\n",
      "File created successfully at: C:\\Users\\prisi\\Desktop\\ECI 2024 Party Wise Results.txt\n",
      "Collected 42 links.\n",
      "Collected 543 links.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "# URL of the page to be scraped\n",
    "url = \"https://results.eci.gov.in/PcResultGenJune2024/index.htm\"\n",
    "base_url = \"https://results.eci.gov.in/PcResultGenJune2024/\"\n",
    "\n",
    "# Make a request to the website\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find the table containing the election results\n",
    "table = soup.find('table', {'class': 'table'})\n",
    "\n",
    "# List to store URLs\n",
    "won_links = []\n",
    "constituency_links = []\n",
    "\n",
    "# Path to the desktop\n",
    "desktop_path = os.path.join(os.path.expanduser(\"~\"), \"Desktop\")\n",
    "file_path = os.path.join(desktop_path, \"ECI 2024 Party Wise Results.txt\")\n",
    "\n",
    "# Print the paths for debugging\n",
    "print(f\"Desktop path: {desktop_path}\")\n",
    "print(f\"File path: {file_path}\")\n",
    "\n",
    "# Ensure the desktop directory exists\n",
    "if not os.path.exists(desktop_path):\n",
    "    print(f\"Desktop path does not exist: {desktop_path}\")\n",
    "    try:\n",
    "        os.makedirs(desktop_path)\n",
    "        print(f\"Desktop path created: {desktop_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating desktop path: {e}\")\n",
    "else:\n",
    "    print(f\"Desktop path exists: {desktop_path}\")\n",
    "\n",
    "# Ensure the file can be created\n",
    "try:\n",
    "    with open(file_path, 'w') as file:\n",
    "        print(f\"File created successfully at: {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating file: {e}\")\n",
    "\n",
    "# Loop through each row in the table\n",
    "for row in table.find_all('tr')[1:]:  # Skipping the header row\n",
    "    cells = row.find_all('td')\n",
    "    if len(cells) > 0:\n",
    "        won_link = cells[1].find('a')['href'] if cells[1].find('a') else None\n",
    "        if won_link:\n",
    "            full_link = base_url + won_link\n",
    "            won_links.append(full_link)\n",
    "\n",
    "print(f\"Collected {len(won_links)} links.\")\n",
    "\n",
    "# Open the file to write\n",
    "with open(file_path, 'w') as file:\n",
    "    # Scraping url for each party to get list of constituency links\n",
    "    for link in won_links:\n",
    "        response = requests.get(link)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "            # Find the table containing the list of winning candidates\n",
    "            table = soup.find('table', {'class': 'table table-striped table-bordered'}) \n",
    "            if table:\n",
    "                for row in table.find_all('tr')[1:]:  # Skipping the header row\n",
    "                    cells = row.find_all('td')\n",
    "                    if len(cells) > 0:\n",
    "                        constituency_link = cells[1].find('a')['href'] if cells[1].find('a') else None\n",
    "                        if constituency_link:\n",
    "                            full_link2 = base_url + constituency_link\n",
    "                            new_full_link2 = full_link2.replace(\"candidateswise-\", \"Constituencywise\")\n",
    "                            constituency_links.append(new_full_link2)\n",
    "                            file.write(f\"{new_full_link2}\\n\")\n",
    "\n",
    "print(f\"Collected {len(constituency_links)} links.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8c7835-95c1-48cb-a41c-cfd01d92d551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98acb68-5ee9-4d96-b6b8-bc2299049695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee3c9c9-5de3-47ba-bd1a-a20328d08322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b20d788-5076-41e7-b7f4-e878171a60d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96158e-d908-405e-8300-d11c7a12d99e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aa4b88-5365-43cd-8021-1b2e9445c03e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35f3537-a61d-42a8-aea9-a87abc89e220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b3bbde-d6e7-493a-be00-b8e5150ddba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aa19bf-e9c3-4ecb-ae70-d430ebc6d076",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
